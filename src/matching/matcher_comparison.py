"""
Matcher Comparison Utility

–ü–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —Ç—Ä–µ—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ matching
"""
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
import statistics

from .job_model import Job, MatchResult
from .semantic_matcher import SemanticMatcher
from .tfidf_matcher import TFIDFMatcher
from .llm_matcher import LLMMatcher

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
from resume_parser.models import Resume

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ComparisonResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–∞—Ç—á–µ—Ä–æ–≤"""
    resume_id: str
    job_id: str

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –∫–∞–∂–¥–æ–≥–æ –º–∞—Ç—á–µ—Ä–∞
    semantic_result: Optional[MatchResult] = None
    tfidf_result: Optional[MatchResult] = None
    llm_result: Optional[MatchResult] = None

    # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    average_score: float = 0.0
    median_score: float = 0.0
    score_variance: float = 0.0
    agreement_level: str = "unknown"  # high, medium, low

    def __post_init__(self):
        """–í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        scores = []

        if self.semantic_result:
            scores.append(self.semantic_result.overall_score)
        if self.tfidf_result:
            scores.append(self.tfidf_result.overall_score)
        if self.llm_result:
            scores.append(self.llm_result.overall_score)

        if len(scores) >= 2:
            self.average_score = statistics.mean(scores)
            self.median_score = statistics.median(scores)
            self.score_variance = statistics.variance(scores) if len(scores) > 1 else 0.0

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
            if self.score_variance < 0.01:
                self.agreement_level = "high"
            elif self.score_variance < 0.05:
                self.agreement_level = "medium"
            else:
                self.agreement_level = "low"


class MatcherComparison:
    """
    –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ matching

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ —Ç—Ä–∏ –º–∞—Ç—á–µ—Ä–∞ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    """

    def __init__(
        self,
        use_semantic: bool = True,
        use_tfidf: bool = True,
        use_llm: bool = False,
        openai_api_key: Optional[str] = None
    ):
        """
        Args:
            use_semantic: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Semantic Matcher
            use_tfidf: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TF-IDF Matcher
            use_llm: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM Matcher
            openai_api_key: API –∫–ª—é—á –¥–ª—è OpenAI (–µ—Å–ª–∏ use_llm=True)
        """
        self.matchers = {}

        if use_semantic:
            try:
                self.matchers['semantic'] = SemanticMatcher()
                logger.info("Semantic Matcher initialized")
            except Exception as e:
                logger.warning(f"Could not initialize Semantic Matcher: {e}")

        if use_tfidf:
            try:
                self.matchers['tfidf'] = TFIDFMatcher()
                logger.info("TF-IDF Matcher initialized")
            except Exception as e:
                logger.warning(f"Could not initialize TF-IDF Matcher: {e}")

        if use_llm:
            try:
                self.matchers['llm'] = LLMMatcher(api_key=openai_api_key)
                logger.info("LLM Matcher initialized")
            except Exception as e:
                logger.warning(f"Could not initialize LLM Matcher: {e}")

        if not self.matchers:
            logger.error("No matchers available!")

    def compare_single(self, resume: Resume, job: Job) -> ComparisonResult:
        """
        –°—Ä–∞–≤–Ω–∏—Ç—å –æ–¥–Ω–æ —Ä–µ–∑—é–º–µ —Å –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–µ–π –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–∞—Ç—á–µ—Ä—ã

        Args:
            resume: –†–µ–∑—é–º–µ
            job: –í–∞–∫–∞–Ω—Å–∏—è

        Returns:
            ComparisonResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ç –≤—Å–µ—Ö –º–∞—Ç—á–µ—Ä–æ–≤
        """
        result = ComparisonResult(
            resume_id=resume.file_name,
            job_id=job.job_id
        )

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–∞–∂–¥—ã–π –º–∞—Ç—á–µ—Ä
        if 'semantic' in self.matchers:
            try:
                result.semantic_result = self.matchers['semantic'].match(resume, job)
                logger.info(f"Semantic match: {result.semantic_result.overall_score:.1%}")
            except Exception as e:
                logger.error(f"Semantic matching failed: {e}")

        if 'tfidf' in self.matchers:
            try:
                result.tfidf_result = self.matchers['tfidf'].match(resume, job)
                logger.info(f"TF-IDF match: {result.tfidf_result.overall_score:.1%}")
            except Exception as e:
                logger.error(f"TF-IDF matching failed: {e}")

        if 'llm' in self.matchers:
            try:
                result.llm_result = self.matchers['llm'].match(resume, job)
                logger.info(f"LLM match: {result.llm_result.overall_score:.1%}")
            except Exception as e:
                logger.error(f"LLM matching failed: {e}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –≤ __post_init__
        return result

    def compare_many(
        self,
        resumes: List[Resume],
        job: Job,
        top_n: int = 5
    ) -> List[ComparisonResult]:
        """
        –°—Ä–∞–≤–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—é–º–µ —Å –≤–∞–∫–∞–Ω—Å–∏–µ–π

        Args:
            resumes: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—é–º–µ
            job: –í–∞–∫–∞–Ω—Å–∏—è
            top_n: –°–∫–æ–ª—å–∫–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–µ—Ä–Ω—É—Ç—å

        Returns:
            –°–ø–∏—Å–æ–∫ ComparisonResult, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ average_score
        """
        results = []

        for resume in resumes:
            comparison = self.compare_single(resume, job)
            results.append(comparison)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É score
        results.sort(key=lambda x: x.average_score, reverse=True)

        return results[:top_n]

    def print_comparison(self, comparison: ComparisonResult):
        """
        –ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

        Args:
            comparison: –†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        print("\n" + "=" * 70)
        print(f"Comparison Results: {comparison.resume_id} vs {comparison.job_id}")
        print("=" * 70)

        print(f"\n{'Matcher':<20} {'Score':<10} {'Semantic/LLM':<15} {'Skills':<10}")
        print("-" * 70)

        if comparison.semantic_result:
            r = comparison.semantic_result
            print(f"{'Sentence-BERT':<20} {r.overall_score:<10.1%} "
                  f"{r.semantic_similarity:<15.1%} {r.skills_match:<10.1%}")

        if comparison.tfidf_result:
            r = comparison.tfidf_result
            sem = r.semantic_similarity if r.semantic_similarity else 0.0
            print(f"{'TF-IDF':<20} {r.overall_score:<10.1%} "
                  f"{sem:<15.1%} {r.skills_match:<10.1%}")

        if comparison.llm_result:
            r = comparison.llm_result
            sem = r.semantic_similarity if r.semantic_similarity else 0.0
            print(f"{'LLM (GPT)':<20} {r.overall_score:<10.1%} "
                  f"{sem:<15.1%} {r.skills_match:<10.1%}")

        print("\n" + "-" * 70)
        print(f"Average Score: {comparison.average_score:.1%}")
        print(f"Median Score: {comparison.median_score:.1%}")
        print(f"Variance: {comparison.score_variance:.4f}")
        print(f"Agreement Level: {comparison.agreement_level.upper()}")

        # Skills analysis
        if comparison.semantic_result:
            r = comparison.semantic_result
            print(f"\nüìä Skills Analysis:")
            print(f"  Matched: {', '.join(r.matched_skills[:8])}")
            if r.missing_skills:
                print(f"  Missing: {', '.join(r.missing_skills[:5])}")

        # LLM explanation
        if comparison.llm_result and comparison.llm_result.explanation:
            print(f"\nüí° LLM Explanation:")
            print(f"  {comparison.llm_result.explanation[:200]}...")

    def get_best_matcher(self, comparisons: List[ComparisonResult]) -> Dict[str, int]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞–∫–æ–π –º–∞—Ç—á–µ—Ä —á–∞—â–µ –≤—Å–µ–≥–æ –¥–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

        Args:
            comparisons: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

        Returns:
            –°–ª–æ–≤–∞—Ä—å {matcher_name: count} —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–æ–±–µ–¥
        """
        wins = {'semantic': 0, 'tfidf': 0, 'llm': 0}

        for comp in comparisons:
            scores = {}

            if comp.semantic_result:
                scores['semantic'] = comp.semantic_result.overall_score
            if comp.tfidf_result:
                scores['tfidf'] = comp.tfidf_result.overall_score
            if comp.llm_result:
                scores['llm'] = comp.llm_result.overall_score

            if scores:
                winner = max(scores.items(), key=lambda x: x[1])
                wins[winner[0]] += 1

        return wins

    def calculate_correlation(self, comparisons: List[ComparisonResult]) -> Dict[str, float]:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ä–∞–∑–Ω—ã—Ö –º–∞—Ç—á–µ—Ä–æ–≤

        Args:
            comparisons: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º–∏ –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏ –º–∞—Ç—á–µ—Ä–æ–≤
        """
        semantic_scores = []
        tfidf_scores = []
        llm_scores = []

        for comp in comparisons:
            if comp.semantic_result:
                semantic_scores.append(comp.semantic_result.overall_score)
            if comp.tfidf_result:
                tfidf_scores.append(comp.tfidf_result.overall_score)
            if comp.llm_result:
                llm_scores.append(comp.llm_result.overall_score)

        correlations = {}

        # –ü—Ä–æ—Å—Ç–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞
        if len(semantic_scores) == len(tfidf_scores) and len(semantic_scores) > 1:
            try:
                corr = statistics.correlation(semantic_scores, tfidf_scores)
                correlations['semantic_vs_tfidf'] = corr
            except:
                pass

        if len(semantic_scores) == len(llm_scores) and len(semantic_scores) > 1:
            try:
                corr = statistics.correlation(semantic_scores, llm_scores)
                correlations['semantic_vs_llm'] = corr
            except:
                pass

        if len(tfidf_scores) == len(llm_scores) and len(tfidf_scores) > 1:
            try:
                corr = statistics.correlation(tfidf_scores, llm_scores)
                correlations['tfidf_vs_llm'] = corr
            except:
                pass

        return correlations
